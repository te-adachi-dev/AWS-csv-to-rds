# AWS ETL System - CSV to RDS PostgreSQL

S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•çš„ã«RDS PostgreSQLã«å–ã‚Šè¾¼ã‚€ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹ETLã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

## ðŸš€ ä¸»ãªæ©Ÿèƒ½

- **è‡ªå‹•CSVå‡¦ç†**: S3ã«CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨è‡ªå‹•çš„ã«RDSã«ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
- **å‹•çš„ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ**: CSVãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰è‡ªå‹•çš„ã«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
- **SQLã‚¯ã‚¨ãƒªå®Ÿè¡Œ**: LambdaçµŒç”±ã§RDSã«ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã€çµæžœã‚’S3ã«å‡ºåŠ›
- **åˆæœŸåŒ–å‡¦ç†**: S3ã«é…ç½®ã—ãŸSQLãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è‡ªå‹•ä½œæˆ

## ðŸ“‹ å‰ææ¡ä»¶

- AWS CLI v1ã¾ãŸã¯v2ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
- AWS ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¨é©åˆ‡ãªæ¨©é™ï¼ˆAdministratoræŽ¨å¥¨ï¼‰
- Python 3.xï¼ˆLambdaé–¢æ•°ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨ï¼‰
- Git

## ðŸ› ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/te-adachi-dev/AWS-csv-to-rds
cd AWS-csv-to-rds

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ç¢ºèª
tree
```

### 2. AWSç’°å¢ƒã®è¨­å®š

```bash
# AWS CLIã®è¨­å®šï¼ˆæœªè¨­å®šã®å ´åˆï¼‰
aws configure

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆå¿…é ˆï¼‰
export AWS_DEFAULT_REGION=us-east-2  # ä½¿ç”¨ã™ã‚‹ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã«å¤‰æ›´

# åˆ¥ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã®ä¾‹
# export AWS_DEFAULT_REGION=ap-northeast-1  # æ±äº¬ãƒªãƒ¼ã‚¸ãƒ§ãƒ³
# export AWS_DEFAULT_REGION=eu-west-1      # ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰
```

### 3. ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ä¿å­˜ç”¨S3ãƒã‚±ãƒƒãƒˆã®ä½œæˆ

```bash
# ãƒã‚±ãƒƒãƒˆåã‚’æ±ºå®šï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¦ãƒ‹ãƒ¼ã‚¯ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰
BUCKET_NAME="etl-csv-to-rds-postgresql-source-$(date +%Y%m%d)-$RANDOM"

# ãƒã‚±ãƒƒãƒˆä½œæˆ
aws s3 mb s3://$BUCKET_NAME

# ä½œæˆç¢ºèª
aws s3 ls | grep $BUCKET_NAME

echo "Source Bucket: $BUCKET_NAME"
```

### 4. Lambdaé–¢æ•°ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°

```bash
# Lambdaé–¢æ•°ã®zipãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
cd lambda-code

# CSV Processor
if [ ! -f csv_processor.zip ]; then
    zip csv_processor.zip csv_processor.py
fi

# Query Executor
if [ ! -f query_executor.zip ]; then
    zip query_executor.zip query_executor.py
fi

# Table Creator
if [ ! -f table_creator.zip ]; then
    zip table_creator.zip table_creator.py
fi

cd ..
```

### 5. psycopg2ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æº–å‚™

```bash
# ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
if [ ! -f layers/psycopg2-layer.zip ]; then
    # äº‹å‰ãƒ“ãƒ«ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    cp layers/build/psycopg2-layer.zip layers/
fi

# ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
ls -la layers/psycopg2-layer.zip
```

## ðŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤

### ãƒ¯ãƒ³ã‚³ãƒžãƒ³ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤

```bash
# ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œï¼ˆ15-20åˆ†ã‹ã‹ã‚Šã¾ã™ï¼‰
./deploy-simple.sh $BUCKET_NAME

# ã¾ãŸã¯ã€ç›´æŽ¥ãƒã‚±ãƒƒãƒˆåã‚’æŒ‡å®š
./deploy-simple.sh etl-csv-to-rds-postgresql-source-20240614-12345
```

### ãƒ‡ãƒ—ãƒ­ã‚¤æˆåŠŸã®ç¢ºèª

ãƒ‡ãƒ—ãƒ­ã‚¤ãŒæˆåŠŸã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ãªå‡ºåŠ›ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ï¼š

```
âœ“ ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†ï¼

=== æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ— ===
1. ãƒ†ã‚¹ãƒˆç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰:
   aws s3 cp your-file.csv s3://etl-csv-to-rds-postgresql-data-xxxxxxxx-test/csv/

2. Lambdaé–¢æ•°ãƒ­ã‚°ã®ç¢ºèª:
   aws logs tail /aws/lambda/etl-csv-to-rds-postgresql-csv-processor --follow

3. RDSæŽ¥ç¶šç¢ºèª (VPCå†…ã®EC2ã‹ã‚‰):
   psql -h etl-csv-to-rds-postgresql-pg-test.xxxxx.rds.amazonaws.com -U postgres -d postgres
```

## ðŸ“Š ä½¿ç”¨æ–¹æ³•

### 1. CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†

```bash
# ãƒ‡ãƒ¼ã‚¿ãƒã‚±ãƒƒãƒˆåã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®š
DATA_BUCKET=$(aws cloudformation describe-stacks \
  --stack-name etl-csv-to-rds-postgresql \
  --query 'Stacks[0].Outputs[?OutputKey==`DataBucketName`].OutputValue' \
  --output text)

# ãƒ†ã‚¹ãƒˆç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
cat > products.csv << EOF
product_id,name,quantity,price,category
1,ãƒŽãƒ¼ãƒˆPC,10,85000,é›»å­æ©Ÿå™¨
2,ãƒžã‚¦ã‚¹,50,2500,ã‚¢ã‚¯ã‚»ã‚µãƒª
3,ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰,30,5500,ã‚¢ã‚¯ã‚»ã‚µãƒª
EOF

# S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè‡ªå‹•çš„ã«å‡¦ç†ã•ã‚Œã¾ã™ï¼‰
aws s3 cp products.csv s3://$DATA_BUCKET/csv/
```

### 2. ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªï¼ˆQueryExecutorä½¿ç”¨ï¼‰

```bash
# ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã®ç¢ºèª
aws lambda invoke \
  --function-name etl-csv-to-rds-postgresql-query-executor \
  --payload '{"sql": "SELECT tablename FROM pg_tables WHERE schemaname = '\''public'\'' ORDER BY tablename;"}' \
  result.json

cat result.json | jq .

# ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆJSONå½¢å¼ï¼‰
aws lambda invoke \
  --function-name etl-csv-to-rds-postgresql-query-executor \
  --payload '{"sql": "SELECT * FROM products_20240614_123456 LIMIT 10;", "output_format": "json"}' \
  result.json

cat result.json | jq .
```

### 3. ã‚«ã‚¹ã‚¿ãƒ SQLã®å®Ÿè¡Œ

```bash
# é›†è¨ˆã‚¯ã‚¨ãƒªã®ä¾‹
aws lambda invoke \
  --function-name etl-csv-to-rds-postgresql-query-executor \
  --payload '{
    "sql": "SELECT category, COUNT(*) as count, SUM(price * quantity) as total_value FROM products_20240614_123456 GROUP BY category;",
    "output_format": "csv",
    "output_name": "category_summary"
  }' \
  result.json
```

## ðŸ” ãƒ­ã‚°ã®ç¢ºèª

### AWS CLI v2ã®å ´åˆ
```bash
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ç›£è¦–
aws logs tail /aws/lambda/etl-csv-to-rds-postgresql-csv-processor --follow
```

### AWS CLI v1ã®å ´åˆ
```bash
# éŽåŽ»5åˆ†ã®ãƒ­ã‚°ã‚’ç¢ºèª
aws logs filter-log-events \
  --log-group-name /aws/lambda/etl-csv-to-rds-postgresql-csv-processor \
  --start-time $(($(date +%s -d '5 minutes ago') * 1000)) \
  --query 'events[*].message' \
  --output text
```

## ðŸ›¡ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦æ³•

#### 1. TemplateURL must be a supported URL
```bash
# åŽŸå› : AWS_DEFAULT_REGIONãŒæœªè¨­å®š
# è§£æ±ºæ–¹æ³•:
export AWS_DEFAULT_REGION=us-east-2
```

#### 2. CSVã®`id`ã‚«ãƒ©ãƒ ã‚¨ãƒ©ãƒ¼
```
ã‚¨ãƒ©ãƒ¼: column "id" specified more than once
```
- åŽŸå› : Lambdaé–¢æ•°ãŒè‡ªå‹•çš„ã«`id SERIAL PRIMARY KEY`ã‚’è¿½åŠ 
- è§£æ±ºæ–¹æ³•: CSVã®idã‚«ãƒ©ãƒ ã‚’åˆ¥åï¼ˆä¾‹ï¼šproduct_idï¼‰ã«å¤‰æ›´

#### 3. RDSæŽ¥ç¶šã‚¨ãƒ©ãƒ¼
- VPCã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—ã®è¨­å®šã‚’ç¢ºèª

## ðŸ—‘ï¸ ãƒªã‚½ãƒ¼ã‚¹ã®å‰Šé™¤

```bash
# ã‚¹ã‚¿ãƒƒã‚¯ã®å‰Šé™¤ï¼ˆå…¨ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ï¼‰
aws cloudformation delete-stack --stack-name etl-csv-to-rds-postgresql

# å‰Šé™¤å®Œäº†ã®ç¢ºèª
aws cloudformation wait stack-delete-complete --stack-name etl-csv-to-rds-postgresql
```

## ðŸ“ è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒžã‚¤ã‚º

### åˆ¥ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤

1. ç’°å¢ƒå¤‰æ•°ã‚’å¤‰æ›´
```bash
export AWS_DEFAULT_REGION=ap-northeast-1  # æ±äº¬ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã®ä¾‹
```

2. æ–°ã—ã„ã‚½ãƒ¼ã‚¹ãƒã‚±ãƒƒãƒˆã‚’ä½œæˆ
```bash
BUCKET_NAME="etl-csv-rds-tokyo-$(date +%Y%m%d)"
aws s3 mb s3://$BUCKET_NAME
```

3. ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ
```bash
./deploy-simple.sh $BUCKET_NAME
```

### RDSã®è¨­å®šå¤‰æ›´

`cfn-templates/03-database-storage-stack.yaml`ã‚’ç·¨é›†ï¼š

- ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¯ãƒ©ã‚¹: `db.t3.micro` â†’ `db.t3.small`
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚µã‚¤ã‚º: `20` â†’ `100`
- PostgreSQLãƒãƒ¼ã‚¸ãƒ§ãƒ³: `17.4` â†’ å¿…è¦ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³

## ðŸ“š ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     S3      â”‚â”€â”€â”€â”€â–¶â”‚   Lambda    â”‚â”€â”€â”€â”€â–¶â”‚     RDS     â”‚
â”‚  (CSVç½®å ´)  â”‚     â”‚ (å‡¦ç†é–¢æ•°)  â”‚     â”‚(PostgreSQL) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     S3      â”‚
                    â”‚ (çµæžœå‡ºåŠ›)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
